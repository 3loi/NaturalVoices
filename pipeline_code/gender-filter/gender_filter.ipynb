{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./..\")\n",
    "from config import config\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import os, json\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "import librosa\n",
    "from scipy.stats import mode\n",
    "import csv\n",
    "import scipy\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from model import LSTMnet\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from csv import writer\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings & Fix random seed\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Spec_and_Phase(signal, rate):\n",
    "    # signal, rate  = librosa.load(fpath, sr=16000)\n",
    "    signal = signal/np.max(abs(signal)) # Restrict value between [-1,1]\n",
    "    F = librosa.stft(signal, n_fft=512, hop_length=256, win_length=512, window=scipy.signal.hamming)\n",
    "    spec = np.abs(F)\n",
    "    phase = np.angle(F)\n",
    "    spec = np.reshape(spec.T,(spec.shape[1],spec.shape[0]))\n",
    "    return spec\n",
    "\n",
    "# Split Original batch Data into Small-Chunk batch Data Structure with padding\n",
    "def SmallChunkSplitData(data, FrameSize):  \n",
    "    start = 0\n",
    "    Start = [0]\n",
    "    End = []\n",
    "    Split_Data = []\n",
    "    if len(data)>=FrameSize:\n",
    "        equeal_division_data = data[:(int(len(data)/FrameSize))*FrameSize]\n",
    "        split_data = np.split(equeal_division_data,int(len(data)/FrameSize))           \n",
    "        left_data = data[len(equeal_division_data):]\n",
    "        if len(left_data)!=0:            \n",
    "            pad_left_data = pad_sequences(left_data.T, maxlen=FrameSize ,dtype='float', padding='post', truncating='post')\n",
    "            pad_left_data = pad_left_data.T                         \n",
    "            Split_Data = Split_Data + split_data + [pad_left_data]\n",
    "            Start.append(start+len(split_data)+1)\n",
    "            End.append(start+len(split_data)+1)\n",
    "            start = start+len(split_data)+1\n",
    "        else:\n",
    "            Split_Data = Split_Data + split_data\n",
    "            Start.append(start+len(split_data))\n",
    "            End.append(start+len(split_data))\n",
    "            start = start+len(split_data)  \n",
    "    else:\n",
    "        left_data = data\n",
    "        pad_left_data = pad_sequences(left_data.T, maxlen=FrameSize ,dtype='float', padding='post', truncating='post')\n",
    "        pad_left_data = pad_left_data.T\n",
    "        Split_Data = Split_Data + [pad_left_data]        \n",
    "        Start.append(start+1)\n",
    "        End.append(start+1)\n",
    "        start = start+1 \n",
    "    return np.array(Split_Data)\n",
    "\n",
    "def prediction_folder(input_path):\n",
    "    F_Name = []\n",
    "    Pred_Rsl = []\n",
    "    for root, directories, files in os.walk(input_path):\n",
    "        # print(root)\n",
    "        # files = sorted(files)\n",
    "        # print(files)\n",
    "        print('Gender Predictions')\n",
    "        for filename in tqdm(files):\n",
    "            # Join the two strings in order to form the full filepath.\n",
    "            filepath = os.path.join(root, filename)\n",
    "            if '.wav' in filepath:\n",
    "                try:\n",
    "                    data = Spec_and_Phase(filepath)\n",
    "                    chunk_data = SmallChunkSplitData(data, FrameSize=65)\n",
    "                    # Data to torch & float for model input\n",
    "                    chunk_data = torch.from_numpy(chunk_data)\n",
    "                    chunk_data = chunk_data.float().to(device)\n",
    "                    # Pred-chunk-labels for chunk data\n",
    "                    pred_label = model(chunk_data)\n",
    "                    pred_label = (np.round( (Variable(pred_label).data).cpu().numpy() )).reshape(-1)\n",
    "                    # Output Results\n",
    "                    F_Name.append(filename)\n",
    "                    Pred_Rsl.append(mode(pred_label)[0][0])   # output voting result only \n",
    "                except:\n",
    "                    print('Cannot Predict: '+filename)\n",
    "    return F_Name, Pred_Rsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "device = torch.device(config['cude_device'])     \n",
    "\n",
    "# Settings  \n",
    "Training_epochs = 15\n",
    "feat_type = 'Spec'\n",
    "MODEL_STRUCT = 'LSTM'\n",
    "LOADING_PATH = os.path.join('Spec_LSTM_epoch15.pt.tar')\n",
    "\n",
    "# Loading Model Parameters\n",
    "model = LSTMnet(input_dim=257, hidden_dim=150, output_dim=1, num_layers=2)\n",
    "model.load_state_dict(torch.load(LOADING_PATH, map_location=torch.device(device)))\n",
    "model = model.to(device) # if wants to predict on torch.tensor data\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = glob(os.path.join(config['podcast']['path'], \"*.wav\"))\n",
    "audio.sort()\n",
    "audio = {os.path.basename(x).split('.')[0]:x for x in audio}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config['json_path'], 'r') as fp:\n",
    "    all_data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pod in tqdm(all_data.keys()):\n",
    "    for key in list(all_data[pod].keys()):\n",
    "        if all_data[pod][key]['text'] == '':\n",
    "            del all_data[pod][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "for pod in tqdm(all_data.keys()):\n",
    "    try:\n",
    "        wav, sr = librosa.load(audio[pod], sr=16000)\n",
    "    except:\n",
    "        continue\n",
    "    for key, seg in all_data[pod].items():\n",
    "        if 'gender' in all_data[pod][key]:\n",
    "            continue\n",
    "        if len(np.unique(wav[int(seg['start']*sr):int(seg['end']*sr)])) == 1:\n",
    "            continue\n",
    "        seg['end'] = min(seg['end'], (len(wav)-0.05/sr))\n",
    "        data = Spec_and_Phase(wav[int(seg['start']*sr):int(seg['end']*sr)], sr)\n",
    "        chunk_data = SmallChunkSplitData(data, FrameSize=65)\n",
    "        # Data to torch & float for model input\n",
    "        chunk_data = torch.from_numpy(chunk_data)\n",
    "        chunk_data = chunk_data.float().to(device)\n",
    "        # Pred-chunk-labels for chunk data\n",
    "        pred_label = model(chunk_data)\n",
    "        pred_label = (np.round( (Variable(pred_label).data).cpu().numpy() )).reshape(-1)\n",
    "        # Output Results\n",
    "        gender_pred = float(mode(pred_label)[0])   # output voting result only \n",
    "        if gender_pred == 1:\n",
    "            gender_pred = 'Male'\n",
    "        elif gender_pred == 0:\n",
    "            gender_pred = 'Female'\n",
    "        all_data[pod][key]['gender'] = gender_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config['json_path'], 'w') as fp:\n",
    "    json.dump(all_data, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisperx",
   "language": "python",
   "name": "whisperx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
