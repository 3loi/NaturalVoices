{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./..\")\n",
    "from config import config\n",
    "\n",
    "import argparse\n",
    "from smd.data import preprocessing\n",
    "from smd.data import postprocessing\n",
    "import smd.utils as utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.models\n",
    "import keras.backend as K\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from glob import glob\n",
    "import shutil\n",
    "import json\n",
    "import librosa\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_processing(file, mean, std):\n",
    "    if os.path.splitext(file)[1] == '.npy':\n",
    "        spec = np.load(file)\n",
    "    else:\n",
    "        audio = utils.load_audio(file)\n",
    "        spec = preprocessing.get_spectrogram(audio)\n",
    "    mels = preprocessing.get_scaled_mel_bands(spec)\n",
    "    mels = preprocessing.normalize(mels, mean, std)\n",
    "    return mels.T\n",
    "\n",
    "\n",
    "def predict(data_path, output_file, model_path, mean_path, std_path, smoothing):\n",
    "    mean = np.load(mean_path)\n",
    "    std = np.load(std_path)\n",
    "\n",
    "    print(\"Loading the model \" + model_path + \"..\")\n",
    "#     with tf.device('/cpu:0'):\n",
    "    model = keras.models.load_model(model_path)\n",
    "    print(\"Start the prediction..\")\n",
    "\n",
    "    if os.path.isdir(data_path):\n",
    "        if output_file != \"\":\n",
    "            raise ValueError(\"It is possible to set an output file only if the input is a file.\")\n",
    "\n",
    "        files = glob.glob(os.path.abspath(data_path) + \"/*.npy\") + glob.glob(os.path.abspath(data_path) + \"/*.wav\")\n",
    "        for file in tqdm(files):\n",
    "            x = test_data_processing(file, mean, std)\n",
    "            x = x.reshape((1, x.shape[0], x.shape[1]))\n",
    "            output = model.predict(x, batch_size=1, verbose=0)[0].T\n",
    "            output = postprocessing.apply_threshold(output)\n",
    "            if smoothing:\n",
    "                output = postprocessing.smooth_output(output)\n",
    "            annotation = preprocessing.label_to_annotation(output)\n",
    "            output_path = file.replace(\".npy\", '') + \"_prediction.txt\"\n",
    "            output_path = output_path.replace('.wav','')\n",
    "            utils.save_annotation(annotation, output_path)\n",
    "    else:\n",
    "        file = os.path.abspath(data_path)\n",
    "        x = test_data_processing(file, mean, std)\n",
    "        x = x.reshape((1, x.shape[0], x.shape[1]))\n",
    "        output = model.predict(x, batch_size=1, verbose=0)[0].T\n",
    "        output = postprocessing.apply_threshold(output)\n",
    "        if smoothing:\n",
    "            output = postprocessing.smooth_output(output)\n",
    "        annotation = preprocessing.label_to_annotation(output)\n",
    "        if output_file != \"\":\n",
    "            output_path = output_file\n",
    "        else:\n",
    "            output_path = file.replace(\".npy\", '') + \"_prediction.txt\"\n",
    "            output_path = output_path.replace('.wav','')\n",
    "        utils.save_annotation(annotation, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_dir = \"./\"\n",
    "\n",
    "model_path = os.path.join(file_dir, \"speech-music-detection\",\"checkpoint\",\"weights.28-0.13exp1_blstm.hdf5\")\n",
    "\n",
    "# mean_path = root + \"speech-music-detection/checkpoint/mean_gtzan_esc-50_muspeak_musan.npy\"\n",
    "mean_path = os.path.join(file_dir, \"speech-music-detection\",\"checkpoint\",\"mean_gtzan_esc-50_muspeak_musan.npy\")\n",
    "\n",
    "# std_path = root + \"speech-music-detection/checkpoint/std_gtzan_esc-50_muspeak_musan.npy\"\n",
    "std_path = os.path.join(file_dir, \"speech-music-detection\",\"checkpoint\",\"std_gtzan_esc-50_muspeak_musan.npy\")\n",
    "\n",
    "smoothing = True\n",
    "\n",
    "mean = np.load(mean_path)\n",
    "std = np.load(std_path)\n",
    "\n",
    "#load model (keras)\n",
    "print(\"Loading the model \" + model_path + \"..\")\n",
    "# with tf.device('/cpu:0'):\n",
    "model = keras.models.load_model(model_path)\n",
    "print(\"Start the prediction..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config['json_path'], 'r') as fp:\n",
    "    all_data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = glob(os.path.join(config['podcast']['path'], \"*.wav\"))\n",
    "audio.sort()\n",
    "audio = {os.path.basename(x).split('.')[0]:x for x in audio}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_processing(audio, mean, std):\n",
    "    spec = preprocessing.get_spectrogram(audio)\n",
    "    mels = preprocessing.get_scaled_mel_bands(spec)\n",
    "    mels = preprocessing.normalize(mels, mean, std)\n",
    "    return mels.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessPipeline(torch.utils.data.Dataset):\n",
    "    def __init__(self, all_data, audios):\n",
    "        print(\"Organizing the data\")\n",
    "        self.podcasts = []\n",
    "        self.segments = []\n",
    "        self.audios = audios\n",
    "        self.data = all_data\n",
    "        for i, pod_name in enumerate(tqdm(list(all_data.keys()))):\n",
    "            for seg_name, seg in all_data[pod_name].items():\n",
    "                if seg_name != '310': continue\n",
    "                self.podcasts.append(pod_name)\n",
    "                self.segments.append(seg_name)\n",
    "        \n",
    "        \n",
    "        # mean_path = root + \"speech-music-detection/checkpoint/mean_gtzan_esc-50_muspeak_musan.npy\"\n",
    "        mean_path = os.path.join(file_dir, \"speech-music-detection\",\"checkpoint\",\"mean_gtzan_esc-50_muspeak_musan.npy\")\n",
    "\n",
    "        # std_path = root + \"speech-music-detection/checkpoint/std_gtzan_esc-50_muspeak_musan.npy\"\n",
    "        std_path = os.path.join(file_dir, \"speech-music-detection\",\"checkpoint\",\"std_gtzan_esc-50_muspeak_musan.npy\")\n",
    "\n",
    "        smoothing = True\n",
    "\n",
    "        self.mean = np.load(mean_path)\n",
    "        self.std = np.load(std_path)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.podcasts)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" get a video and its label \"\"\"\n",
    "        podcast = self.podcasts[index]\n",
    "        seg_name = self.segments[index]\n",
    "        \n",
    "        seg = self.data[podcast][seg_name]\n",
    "\n",
    "        start = seg['start']\n",
    "        end = seg['end']\n",
    "        wav, sr = librosa.load(self.audios[podcast], offset=start, duration=end-start, sr=16000)\n",
    "        x = test_data_processing(wav, self.mean, self.std)\n",
    "#         x = x.reshape((1, x.shape[0], x.shape[1]))\n",
    "        \n",
    "        return podcast, seg_name, x, wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colate_fun(x):\n",
    "    data = []\n",
    "    lengths = []\n",
    "    for sample in x:\n",
    "        data.append([sample[0], sample[1], np.array(sample[2]), np.array(sample[3])])\n",
    "        lengths.append(len(sample[2]))\n",
    "        \n",
    "    aud = np.zeros((len(x), max(lengths), len(x[0][2][0])))\n",
    "    for i, a in enumerate(data):\n",
    "        aud[i][:len(a[2])] = a[2]\n",
    "    return data, aud, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data = ProcessPipeline(all_data, audio)\n",
    "process_loader = torch.utils.data.DataLoader(process_data, batch_size = 1, num_workers=1, pin_memory=True, shuffle = False,\n",
    "                                              collate_fn=colate_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for info, auds, lengths in tqdm(process_loader):\n",
    "    outputs = model.predict(auds,  verbose=0)\n",
    "    \n",
    "    for i, output, length in zip(info, outputs, lengths):\n",
    "        podcast, seg_name, x, wav =  i\n",
    "        output = output[:length].T\n",
    "        output = postprocessing.apply_threshold(output)\n",
    "        if smoothing:\n",
    "            output = postprocessing.smooth_output(output)\n",
    "        annotation = preprocessing.label_to_annotation(output)\n",
    "        all_data[podcast][seg_name]['speech_music_pred'] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config['json_path'], 'w') as fp:\n",
    "    json.dump(all_data, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisperx",
   "language": "python",
   "name": "whisperx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
